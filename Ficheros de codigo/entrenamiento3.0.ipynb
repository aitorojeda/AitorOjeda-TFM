{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13b30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a810cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf850d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-E9BCQHT:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1824b198348>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Test_spark\").master(\"local[*]\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd932fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad6e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos de entrenamiento y los de prueba\n",
    "ruta=\"C:/Users/Aitor/Desktop/TFM/datos_mod_cab/\"\n",
    "fichero_entrenamiento = \"final_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c805d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accX(g)</th>\n",
       "      <th>accY(g)</th>\n",
       "      <th>accZ(g)</th>\n",
       "      <th>gyrX(o/s)</th>\n",
       "      <th>gyry(o/s)</th>\n",
       "      <th>gyrz(o/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.405300e+06</td>\n",
       "      <td>1.405300e+06</td>\n",
       "      <td>1.405300e+06</td>\n",
       "      <td>1.405300e+06</td>\n",
       "      <td>1.405300e+06</td>\n",
       "      <td>1.405300e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.675167e-01</td>\n",
       "      <td>-1.702909e-01</td>\n",
       "      <td>1.718306e-02</td>\n",
       "      <td>8.716722e-01</td>\n",
       "      <td>4.921452e-02</td>\n",
       "      <td>-7.559592e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.337054e-01</td>\n",
       "      <td>2.643577e-01</td>\n",
       "      <td>2.076064e-01</td>\n",
       "      <td>4.270605e+00</td>\n",
       "      <td>1.050591e+01</td>\n",
       "      <td>6.357781e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.593848e+01</td>\n",
       "      <td>-1.027734e+01</td>\n",
       "      <td>-1.501758e+01</td>\n",
       "      <td>-3.602290e+02</td>\n",
       "      <td>-4.930992e+02</td>\n",
       "      <td>-4.528092e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.828120e-01</td>\n",
       "      <td>-4.663090e-01</td>\n",
       "      <td>-3.418000e-03</td>\n",
       "      <td>5.496180e-01</td>\n",
       "      <td>-2.290080e-01</td>\n",
       "      <td>-1.175573e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.005859e+00</td>\n",
       "      <td>-2.246100e-02</td>\n",
       "      <td>1.611300e-02</td>\n",
       "      <td>8.702290e-01</td>\n",
       "      <td>4.580200e-02</td>\n",
       "      <td>-7.633590e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.014648e+00</td>\n",
       "      <td>6.348000e-03</td>\n",
       "      <td>3.564500e-02</td>\n",
       "      <td>1.114504e+00</td>\n",
       "      <td>2.900760e-01</td>\n",
       "      <td>-5.343510e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.599951e+01</td>\n",
       "      <td>8.896484e+00</td>\n",
       "      <td>1.548096e+01</td>\n",
       "      <td>1.594504e+02</td>\n",
       "      <td>4.930534e+02</td>\n",
       "      <td>4.970076e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            accX(g)       accY(g)       accZ(g)     gyrX(o/s)     gyry(o/s)  \\\n",
       "count  1.405300e+06  1.405300e+06  1.405300e+06  1.405300e+06  1.405300e+06   \n",
       "mean   9.675167e-01 -1.702909e-01  1.718306e-02  8.716722e-01  4.921452e-02   \n",
       "std    5.337054e-01  2.643577e-01  2.076064e-01  4.270605e+00  1.050591e+01   \n",
       "min   -1.593848e+01 -1.027734e+01 -1.501758e+01 -3.602290e+02 -4.930992e+02   \n",
       "25%    8.828120e-01 -4.663090e-01 -3.418000e-03  5.496180e-01 -2.290080e-01   \n",
       "50%    1.005859e+00 -2.246100e-02  1.611300e-02  8.702290e-01  4.580200e-02   \n",
       "75%    1.014648e+00  6.348000e-03  3.564500e-02  1.114504e+00  2.900760e-01   \n",
       "max    1.599951e+01  8.896484e+00  1.548096e+01  1.594504e+02  4.930534e+02   \n",
       "\n",
       "          gyrz(o/s)  \n",
       "count  1.405300e+06  \n",
       "mean  -7.559592e-01  \n",
       "std    6.357781e+01  \n",
       "min   -4.528092e+02  \n",
       "25%   -1.175573e+00  \n",
       "50%   -7.633590e-01  \n",
       "75%   -5.343510e-01  \n",
       "max    4.970076e+02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "# Import data\n",
    "df_train = pd.read_csv(ruta+fichero_entrenamiento, header=0)\n",
    "#df_train = df_train.drop(columns=['time(us)','accX(g)','accY(g)','accZ(g)','gyrX(o/s)','gyry(o/s)'])\n",
    "df_train = df_train.drop(columns=['user_ID','attemp','time(us)'])\n",
    "# Print first 10 samples\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "023ad268",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['time(us)'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-27e7d6c9499b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Import data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruta\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfichero_entrenamiento\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time(us)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Print first 10 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_TFM\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4313\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4314\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4315\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4316\u001b[0m         )\n\u001b[0;32m   4317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_TFM\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_TFM\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_TFM\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['time(us)'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "# Import data\n",
    "df_train = pd.read_csv(ruta+fichero_entrenamiento, header=0)\n",
    "df_train = df_train.drop(columns=['time(us)'])\n",
    "# Print first 10 samples\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "175c9e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_ID  attemp  gyrz(o/s)\n",
      "0              1       1  -0.778626\n",
      "1              1       1  -0.580153\n",
      "2              1       1  -0.625954\n",
      "3              1       1  -0.625954\n",
      "4              1       1  -0.916031\n",
      "...          ...     ...        ...\n",
      "1405295       47      20  -0.549618\n",
      "1405296       47      20  -0.595420\n",
      "1405297       47      20  -0.824427\n",
      "1405298       47      20  -0.671756\n",
      "1405299       47      20  -0.488550\n",
      "\n",
      "[1405300 rows x 3 columns] 0           1\n",
      "1           1\n",
      "2           1\n",
      "3           1\n",
      "4           1\n",
      "           ..\n",
      "1405295    47\n",
      "1405296    47\n",
      "1405297    47\n",
      "1405298    47\n",
      "1405299    47\n",
      "Name: user_ID, Length: 1405300, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Divide data into features X and target (Classes) Y\n",
    "X_train = df_train.iloc[:,0:3]\n",
    "Y_train = df_train.iloc[:,0]\n",
    "print(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "907a4167",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1         2         3\n",
      "0       0.0  0.0  0.515307  0.412609\n",
      "1       0.0  0.0  0.515291  0.412844\n",
      "2       0.0  0.0  0.515196  0.412790\n",
      "3       0.0  0.0  0.515465  0.412790\n",
      "4       0.0  0.0  0.515481  0.412447\n",
      "...     ...  ...       ...       ...\n",
      "351320  1.0  1.0  0.515402  0.413060\n",
      "351321  1.0  1.0  0.515244  0.412627\n",
      "351322  1.0  1.0  0.515433  0.412736\n",
      "351323  1.0  1.0  0.514944  0.412573\n",
      "351324  1.0  1.0  0.514912  0.412934\n",
      "\n",
      "[351325 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalize features within range 0 (minimum) and 1 (maximum)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c174044f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1   2   3   4   5   6   7   8   9   10  ...  38  39  40  41  42  43  \\\n",
      "0        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "1        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "2        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "3        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "4        1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
      "351320   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "351321   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "351322   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "351323   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "351324   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
      "\n",
      "        44  45  46  47  \n",
      "0        0   0   0   0  \n",
      "1        0   0   0   0  \n",
      "2        0   0   0   0  \n",
      "3        0   0   0   0  \n",
      "4        0   0   0   0  \n",
      "...     ..  ..  ..  ..  \n",
      "351320   0   0   0   1  \n",
      "351321   0   0   0   1  \n",
      "351322   0   0   0   1  \n",
      "351323   0   0   0   1  \n",
      "351324   0   0   0   1  \n",
      "\n",
      "[351325 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert target Y to one hot encoded Y for Neural Network\n",
    "Y_train = pd.get_dummies(Y_train)\n",
    "# If target is in string form, use following code:\n",
    "# First encode target values as integers from string\n",
    "# Then perform one hot encoding\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(Y)\n",
    "# Y = encoder.transform(Y)\n",
    "# Y = np_utils.to_categorical(Y)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca48708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras, convert dataframe to array values (Inbuilt requirement of Keras)\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab1f9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report,precision_recall_fscore_support,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b689f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100.00%\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "accuracy: 100.00%\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "accuracy: 100.00%\n",
      "(0.9999928864608008, 0.9999928840816907, 0.9999928840814917, None)\n",
      "(0.9999928864608008, 0.9999928840816907, 0.9999928840814918, None)\n",
      "accuracy: 100.00%\n",
      "(1.0, 1.0, 1.0, None)\n",
      "(1.0, 1.0, 1.0, None)\n",
      "accuracy: 99.96%\n",
      "(0.9995910816739491, 0.999587276738063, 0.9995872696217447, None)\n",
      "(0.9995910816739493, 0.9995872767380631, 0.9995872696217446, None)\n",
      "99.99% (+/- 0.02%)\n",
      "precision: 99.99% ; f1: 99.99% ; recall: 99.99%\n"
     ]
    }
   ],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "precisionScores = []\n",
    "f1Scores = []\n",
    "recallScores = []\n",
    "for train, test in kfold.split(X_train,Y_train):\n",
    "    X_trained = pd.DataFrame(X_train)\n",
    "    Y_trained = pd.get_dummies(Y_train)\n",
    "    X_training = X_trained.values\n",
    "    Y_training = Y_trained.values\n",
    "  # Create model here\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(47, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X_training[train], Y_training[train], epochs=8, batch_size=512, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_training[test], Y_training[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    #matriz confusion\n",
    "    y_pred=model.predict(X_training[test]) \n",
    "    y_pred=np.argmax(y_pred, axis=1)\n",
    "    y_test=np.argmax(Y_training[test], axis=1)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #print(cm)\n",
    "    scores2 = precision_recall_fscore_support(y_test, y_pred,average='macro',zero_division='warn')\n",
    "    print(precision_recall_fscore_support(y_test, y_pred,average='macro',warn_for ='recall',zero_division='warn'))\n",
    "    precisionScores.append(scores2[0] * 100)\n",
    "    f1Scores.append(scores2[1] * 100)\n",
    "    recallScores.append(scores2[2] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "print(\"precision: %.2f%% ; f1: %.2f%% ; recall: %.2f%%\" % (np.mean(precisionScores),np.mean(f1Scores),np.mean(recallScores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
