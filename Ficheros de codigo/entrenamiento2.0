{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a78240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d692c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "101f895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896b23a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-E9BCQHT:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1661a828288>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Test_spark\").master(\"local[*]\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186c05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos de entrenamiento y los de prueba\n",
    "ruta=\"C:/Users/Aitor/Desktop/TFM/\"\n",
    "fichero_entrenamiento = \"entrenamiento_5_int_final.csv\"\n",
    "fichero_prueba = \"prueba_1_int_final.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b91c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_ID  attemp   accX(g)  gyrz(o/s)\n",
      "0        1      10  1.011230  -0.916031\n",
      "1        1      10  1.008301  -0.778626\n",
      "2        1      10  1.001953  -0.824427\n",
      "3        1      10  1.000000  -0.946565\n",
      "4        1      10  1.005859  -0.870229\n"
     ]
    }
   ],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "# Import data\n",
    "df_train = pd.read_csv(ruta+fichero_entrenamiento, header=0)\n",
    "df_prueba = pd.read_csv(ruta+fichero_prueba, header=0)\n",
    "# Print first 10 samples\n",
    "print(df_prueba.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668e89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_ID  attemp   accX(g)  gyrz(o/s)\n",
      "0             1       1  1.009766  -0.778626\n",
      "1             1       1  1.009277  -0.580153\n",
      "2             1       1  1.006348  -0.625954\n",
      "3             1       1  1.014648  -0.625954\n",
      "4             1       1  1.015137  -0.916031\n",
      "...         ...     ...       ...        ...\n",
      "351320       47       5  1.012695  -0.396947\n",
      "351321       47       5  1.007812  -0.763359\n",
      "351322       47       5  1.013672  -0.671756\n",
      "351323       47       5  0.998535  -0.809160\n",
      "351324       47       5  0.997559  -0.503817\n",
      "\n",
      "[351325 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Divide data into features X and target (Classes) Y\n",
    "X_train = df_train.iloc[:,0:4]\n",
    "Y_train = df_train.iloc[:,0]\n",
    "X_prueba = df_prueba.iloc[:,0:4]\n",
    "Y_prueba = df_prueba.iloc[:,0]\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258f7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features within range 0 (minimum) and 1 (maximum)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "484eed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target Y to one hot encoded Y for Neural Network\n",
    "Y = pd.get_dummies(Y_train)\n",
    "# If target is in string form, use following code:\n",
    "# First encode target values as integers from string\n",
    "# Then perform one hot encoding\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(Y)\n",
    "# Y = encoder.transform(Y)\n",
    "# Y = np_utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccec7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras, convert dataframe to array values (Inbuilt requirement of Keras)\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values\n",
    "X_prueba = X_prueba.values\n",
    "Y_prueba = Y_prueba.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e901c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define baseline model. Then use it in Keras Classifier for the training\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(47, activation = 'softmax')) # Softmax for multi-class classification\n",
    "    # Compile model here\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cbc7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras Classifier and use predefined baseline model\n",
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 8, batch_size = 512, verbose = 0)\n",
    "# Try different values for epoch and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9075511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold Cross Validation\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0b59333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 65.95% (2.07%)\n"
     ]
    }
   ],
   "source": [
    "# Object to describe the result\n",
    "results = cross_val_score(estimator, X, Y, cv = kfold)\n",
    "# Result\n",
    "print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656783e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
